import io, os, math
import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image
import base64

# ========== æ¬¢è¿ç•Œé¢ ==========
if "entered" not in st.session_state:
    st.session_state.entered = False

if not st.session_state.entered:
    st.markdown("""
        <style>
        html, body, [class*="css"] {
            height: 100%;
            margin: 0;
            padding: 0;
        }

        /* âœ… è®©ä¸»å®¹å™¨å……æ»¡å±å¹•å®½åº¦ */
        .block-container {
            padding: 0 !important;
            margin: 0 !important;
            max-width: 100% !important;
            width: 100vw !important;
        }

        /* é¡µé¢æ•´ä½“å‚ç›´æ°´å¹³å±…ä¸­ */
        .welcome-wrapper {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            height: 100vh;
            width: 100vw;
            text-align: center;
            background: linear-gradient(to bottom, #f6fff9, #ffffff);
        }

        .welcome-title {
            font-size: 40px;
            color: #003366;
            font-weight: 700;
            margin-bottom: 15px;
            max-width: 90vw;
            line-height: 1.3;
        }

        .welcome-subtitle {
            font-size: 18px;
            color: #666;
            margin-bottom: 60px;
        }

        /* âœ… æŒ‰é’®åŒºåŸŸå……æ»¡æ•´è¡Œ */
        div.stButton {
            width: 100vw !important;
            display: flex;
            justify-content: center;
        }

        /* âœ… æŒ‰é’®å…¨å®½ & æ— è¾¹æ¡†æ ·å¼ */
        div.stButton > button:first-child {
            width: 100vw;                /* å®½åº¦å æ»¡å…¨å± */
            padding: 1.2em 0;
            font-size: 1.4em;
            font-weight: 600;
            color: white;
            background-color: #3cb371;   /* è‰ç»¿è‰²èƒŒæ™¯ */
            border: none;                /* å»æ‰è¾¹æ¡† */
            border-radius: 0;            /* å»æ‰åœ†è§’ */
            cursor: pointer;
            transition: background 0.3s ease-in-out, transform 0.1s ease-in-out;
        }

        div.stButton > button:first-child:hover {
            background-color: #2e8b57;   /* hover å˜æ·±ä¸€ç‚¹ */
            transform: scale(1.01);
        }

        /* âœ… ç§»åŠ¨ç«¯è‡ªé€‚åº” */
        @media (max-width: 768px) {
            .welcome-title {
                font-size: 26px;
                padding: 0 5vw;
            }
            .welcome-subtitle {
                font-size: 16px;
                margin-bottom: 40px;
            }
            div.stButton > button:first-child {
                font-size: 1.1em;
                padding: 1em 0;
            }
        }
        </style>
    """, unsafe_allow_html=True)

    # é¡µé¢ä¸»ä½“
    st.markdown("""
        <div class="welcome-wrapper">
            <h1 class="welcome-title">
                Use the RUC_AHPâ€“EW Evaluation System to Score Your Suppliers
            </h1>
            <p class="welcome-subtitle">
                â€”â€” Empowering ESG Decision Making with Smart Analytics â€”â€”
            </p>
    """, unsafe_allow_html=True)

    # âœ… å…¨å±æŒ‰é’®ç‰ˆæœ¬
    if st.button("Enter ğŸš€ (Please double-click.)"):
        st.session_state.entered = True

    st.markdown("</div>", unsafe_allow_html=True)
    st.stop()

# ---------------- é¡µé¢è®¾ç½® ----------------
st.set_page_config(
    page_title="RUC_AHPâ€“EW ç»¼åˆè¯„ä»·ç³»ç»Ÿ",
    layout="wide"
)

# ========== é¡µé¢æ¨ªå¹… ==========

banner_path = "ESG_banner.png"  # ä½ çš„æ¨ªå¹…å›¾ç‰‡æ”¾åœ¨ app åŒç›®å½•ä¸‹

if os.path.exists(banner_path):
    # å±•ç¤ºæ¨ªå¹…å›¾ç‰‡ï¼ˆé“ºæ»¡å®½åº¦ï¼‰
    st.image(banner_path, use_container_width=True)
else:
    # å¦‚æœå›¾ç‰‡ç¼ºå¤±ï¼Œæç¤ºä¿¡æ¯
    st.warning("âš ï¸ æœªæ‰¾åˆ° ESG_banner.pngï¼Œè¯·å°†æ¨ªå¹…å›¾ç‰‡æ”¾åœ¨å½“å‰ç›®å½•ä¸‹ã€‚")

# åˆ†å‰²çº¿
st.markdown("<hr style='border: 1px solid #888;'>", unsafe_allow_html=True)

# ---------------- åŸä¸»æ ‡é¢˜ï¼ˆå¯ä¿ç•™ï¼‰ ----------------
st.title("RUC_AHPâ€“EW ç»¼åˆè¯„ä»·ç³»ç»Ÿ")


# ---------------- Utilities ----------------
RI_TABLE = {1:0.00,2:0.00,3:0.58,4:0.90,5:1.12,6:1.24,7:1.32,8:1.41,9:1.45,10:1.49,11:1.51,12:1.48}

def eig_weight_consistency(A):
    vals, vecs = np.linalg.eig(A)
    idx = np.argmax(np.real(vals))
    lam = np.real(vals[idx])
    w = np.real(vecs[:, idx])
    w = np.maximum(w, 0)
    w = w / (w.sum() if w.sum()>0 else 1.0)
    n = A.shape[0]
    CI = (lam - n) / (n - 1) if n>1 else 0.0
    RI = RI_TABLE.get(n, 1.49)
    CR = CI/RI if RI>0 else 0.0
    return w, lam, CI, CR

def row_arith_weight(A):
    col_sum = A.sum(axis=0); col_sum[col_sum==0] = 1.0
    N = A/col_sum
    w = N.mean(axis=1)
    w = np.maximum(w, 0); w = w/(w.sum() if w.sum()>0 else 1.0)
    return w

def row_geo_weight(A):
    with np.errstate(divide='ignore', invalid='ignore'):
        g = np.prod(A, axis=1)**(1.0/A.shape[1])
    g = np.nan_to_num(g, nan=0.0, posinf=0.0, neginf=0.0)
    w = g/(g.sum() if g.sum()>0 else 1.0)
    return w

def ruc_fuse(wE, wA, wG, CR, prior=(0.4,0.3,0.3), metric="L1", mode="geo"):
    W = np.vstack([wE,wA,wG]); wbar = W.mean(axis=0)
    if metric=="L2":
        d = np.array([1.0+np.linalg.norm(W[0]-wbar,2),
                      1.0+np.linalg.norm(W[1]-wbar,2),
                      1.0+np.linalg.norm(W[2]-wbar,2)])
    else:
        d = np.array([1.0+np.linalg.norm(W[0]-wbar,1),
                      1.0+np.linalg.norm(W[1]-wbar,1),
                      1.0+np.linalg.norm(W[2]-wbar,1)])
    pE,pA,pG = prior
    rE = max(0.0, min(1.0, 1.0-CR/0.10))
    gtilde = (np.array([pE,pA,pG])*np.array([rE,1.0,1.0]))/d
    gamma = gtilde/(gtilde.sum() if gtilde.sum()>0 else 1.0)
    if mode=="lin":
        wf = gamma[0]*wE + gamma[1]*wA + gamma[2]*wG
        wf = np.maximum(wf,0); wf = wf/(wf.sum() if wf.sum()>0 else 1.0)
        return wf, gamma
    else:
        wf = (np.maximum(wE,1e-12)**gamma[0])*(np.maximum(wA,1e-12)**gamma[1])*(np.maximum(wG,1e-12)**gamma[2])
        wf = wf/(wf.sum() if wf.sum()>0 else 1.0)
        return wf, gamma

def normalize_minmax(x):
    xmin, xmax = np.nanmin(x), np.nanmax(x)
    rng = xmax-xmin
    if rng<=0: return np.zeros_like(x)
    return (x-xmin)/(rng+1e-12)

# -------------- Step 0: Load hierarchy --------------
st.sidebar.header("æ­¥éª¤å¯¼èˆª")
st.sidebar.markdown("""
## ğŸ§­ æ­¥éª¤å¯¼èˆª

**â… . æ•°æ®å‡†å¤‡**
- ğŸ—‚ï¸ åŠ è½½å±‚çº§å…³ç³»ï¼ˆhierarchy.csvï¼‰

**â…¡. æƒé‡è®¡ç®—**
- âš–ï¸ AHP ä¸¤ä¸¤æ¯”è¾ƒï¼ˆé€å±‚å¼•å¯¼ï¼‰
- ğŸ“ˆ Entropy Weightï¼ˆæ ¹æ®ä¼ä¸šå¾—åˆ†è‡ªåŠ¨è®¡ç®—ï¼‰

**â…¢. æƒé‡èåˆä¸ç»“æœ**
- ğŸ”„ ä¸»å®¢è§‚æƒé‡èåˆï¼ˆAHP Ã— Entropy weightï¼‰
- ğŸ ç»¼åˆè¯„åˆ†ä¸ç»“æœå¯¼å‡º
""")

uploaded_hier = st.file_uploader("ä¸Šä¼ å±‚çº§å…³ç³» CSVï¼ˆåˆ—ï¼šlevel,id,name,parent_id,typeï¼›å·²ä¸ºä½ ç”Ÿæˆ hierarchy.csvï¼‰", type=["csv"])
default_path = "hierarchy.csv"
if uploaded_hier is not None:
    df_hier = pd.read_csv(uploaded_hier)
elif os.path.exists(default_path):
    df_hier = pd.read_csv(default_path)
    st.caption("å·²åŠ è½½æœ¬åœ° hierarchy.csv")
else:
    st.error("è¯·å…ˆä¸Šä¼ å±‚çº§å…³ç³»CSVã€‚"); st.stop()

# Validate
need_cols = {"level","id","name","parent_id","type"}
if not need_cols.issubset(set([c.lower() for c in df_hier.columns])):
    st.error("CSV å¿…é¡»åŒ…å«åˆ—ï¼šlevel,id,name,parent_id,type"); st.stop()

# Standardize cols
df_hier.columns = [c.lower() for c in df_hier.columns]
df_hier["level"] = df_hier["level"].astype(int)

L1_nodes = df_hier[df_hier["level"]==1].copy()
L2_nodes = df_hier[df_hier["level"]==2].copy()
L3_nodes = df_hier[df_hier["level"]==3].copy()

st.success(f"å·²åŠ è½½å±‚çº§ï¼šä¸€çº§ {len(L1_nodes)}ï¼ŒäºŒçº§ {len(L2_nodes)}ï¼Œä¸‰çº§ {len(L3_nodes)}ï¼ˆå¶å­æŒ‡æ ‡ï¼‰ã€‚")

# Groupings
children_L1 = {pid: L2_nodes[L2_nodes["parent_id"]==pid]["id"].tolist() for pid in L1_nodes["id"]}
children_L2 = {pid: L3_nodes[L3_nodes["parent_id"]==pid]["id"].tolist() for pid in L2_nodes["id"]}
name_map = df_hier.set_index("id")["name"].to_dict()
type_map = df_hier[df_hier["level"]==3].set_index("id")["type"].to_dict()

# ---------------- ç¤ºä¾‹æ–‡ä»¶ä¸‹è½½ ----------------
st.subheader("ğŸ“˜ ç¤ºä¾‹æ–‡ä»¶ä¸‹è½½")

# ç¤ºä¾‹ hierarchy.csv å†…å®¹
example_hier = """level,id,name,parent_id,type
1,C1,ESG,,
1,C2,KPI,,
1,C3,DPI,,
2,S1,E,C1,
2,S2,S,C1,
2,S3,G,C1,
3,T1,ç¢³æ’æ”¾,S1,cost
3,T2,æ°´èµ„æºç®¡ç†,S1,cost
3,T3,åºŸç‰©ç®¡ç†ä¸å¾ªç¯åˆ©ç”¨,S1,benefit
3,T4,åŒ–å­¦å“ç®¡ç†,S1,benefit
3,T5,å¯æŒç»­é¢æ–™ä½¿ç”¨,S1,benefit
3,T6,åŠ³å·¥æ¡ä»¶å’Œå‘˜å·¥æƒç›Š,S2,benefit
3,T7,å¤šå…ƒåŒ–ä¸åŒ…å®¹æ€§,S2,benefit
3,T8,ä¾›åº”é“¾é€æ˜åº¦ä¸å…¬å¹³äº¤æ˜“,S2,benefit
3,T9,æ•™è‚²ä¸åŸ¹è®­,S2,benefit
3,T10,ä¼ä¸šæ²»ç†ç»“æ„ä¸é€æ˜åº¦,S3,benefit
3,T11,åˆè§„æ€§ä¸æ³•å¾‹éµå®ˆ,S3,benefit
3,T12,æ•°æ®ä¿æŠ¤ä¸ä¿¡æ¯å®‰å…¨,S3,cost
3,T13,é£é™©ç®¡ç†ä¸å±æœºåº”å¯¹,S3,benefit
2,K1,æˆæœ¬æ•ˆç›Šç®¡ç†,C2,
2,K2,ä¾›åº”é“¾å“åº”èƒ½åŠ›,C2,
2,K3,è´¨é‡ç®¡ç†,C2,
2,K4,å®‰å…¨åˆè§„æ€§,C2,
3,T14,æˆæœ¬æ§åˆ¶ç‡,K1,cost
3,T15,å•ä½äº§å“æˆæœ¬ä¸‹é™ç‡,K1,benefit
3,T16,æˆæœ¬ä¼˜åŒ–åˆ›æ–°å®è·µ,K1,benefit
3,T17,è´§æœŸè¾¾æˆç‡,K2,benefit
3,T18,ä¾›åº”é“¾ä¸­æ–­å¿«é€Ÿæ¢å¤èƒ½åŠ›,K2,cost
3,T19,ä¾›åº”é“¾æ•æ·æ€§,K2,benefit
3,T20,äº§å“ä¸€è‡´æ€§,K3,benefit
3,T21,å®¢æˆ·æ»¡æ„åº¦æŒ‡æ•°,K3,benefit
3,T22,è´¨é‡æ”¹è¿›æ–¹æ¡ˆå®æ–½ç‡,K3,benefit
3,T23,å®‰å…¨äº‹æ•…å‘ç”Ÿé¢‘ç‡,K4,cost
3,T24,æ³•è§„åˆè§„æ£€æŸ¥é€šè¿‡ç‡,K4,benefit
3,T25,å®‰å…¨é£é™©é¢„é˜²æªæ–½å®æ–½ç¨‹åº¦,K4,benefit
2,D1,æ ¸å¿ƒèƒ½åŠ›ä¸é¢†å¯¼åŠ›,C3,
2,D2,åˆ›æ–°ä¸ç ”å‘èƒ½åŠ›,C3,
2,D3,è¿è¥æ‰§è¡ŒåŠ›,C3,
2,D4,ä¾›åº”é“¾ç®¡ç†èƒ½åŠ›,C3,
3,T26,é•¿æœŸæˆ˜ç•¥è§„åˆ’èƒ½åŠ›,D1,benefit
3,T27,å¸‚åœºè¶‹åŠ¿åˆ†æä¸å†³ç­–èƒ½åŠ›,D1,benefit
3,T28,é£é™©é¢„è§ä¸åº”å¯¹èƒ½åŠ›,D1,benefit
3,T29,æ–°äº§å“ç ”å‘å‘¨æœŸ,D2,cost
3,T30,æŠ€æœ¯åˆ›æ–°æŠ•å…¥æ¯”ä¾‹,D2,benefit
3,T31,çŸ¥è¯†äº§æƒä¿æŠ¤ä¸åˆ©ç”¨,D2,benefit
3,T32,èµ„æºæ•´åˆä¸åˆ©ç”¨æ•ˆç‡,D3,benefit
3,T33,æˆæœ¬æ§åˆ¶èƒ½åŠ›,D3,benefit
3,T34,ç»©æ•ˆé©±åŠ¨çš„å›¢é˜Ÿç®¡ç†,D3,benefit
3,T35,ä¾›åº”å•†å…³ç³»ç®¡ç†èƒ½åŠ›,D4,benefit
3,T36,åº“å­˜ä¸ç‰©æµä¼˜åŒ–èƒ½åŠ›,D4,cost
3,T37,ä¾›åº”é“¾ååŒåˆ›æ–°,D4,benefit
"""

# ç¤ºä¾‹ company_scores_demo.csv å†…å®¹
example_scores = """Company,T1,T2,T3,T4,T5,T6,T7,T8,T9,T10,T11,T12,T13,T14,T15,T16,T17,T18,T19,T20,T21,T22,T23,T24,T25,T26,T27,T28,T29,T30,T31,T32,T33,T34,T35,T36,T37
å…¬å¸A,80,72,88,83,77,92,86,84,79,88,91,73,85,82,87,89,90,75,86,88,85,87,70,89,84,88,85,75,90,88,86,83,82,84,85,78,89
å…¬å¸B,85,76,90,85,79,90,85,82,81,84,87,70,83,80,85,87,88,74,85,87,82,86,72,88,83,85,84,74,88,86,85,84,83,85,86,80,87
å…¬å¸C,88,74,91,86,80,93,88,85,82,86,88,72,86,83,88,89,90,76,87,89,84,88,73,89,85,87,86,76,91,87,86,85,84,86,87,82,88
å…¬å¸D,78,70,85,80,75,88,82,80,77,83,86,68,82,78,83,85,86,70,82,84,80,84,68,85,81,84,82,70,85,83,82,80,79,81,83,76,84
å…¬å¸E,92,80,94,90,85,96,92,88,85,90,95,76,89,88,92,93,95,80,90,92,89,92,75,93,88,91,90,78,95,91,90,88,87,89,90,84,91
å…¬å¸F,84,75,89,84,78,91,85,82,80,85,89,70,84,81,86,88,89,73,84,86,82,86,71,87,83,86,84,73,87,85,84,83,82,84,85,79,86
å…¬å¸G,90,78,93,88,83,95,90,86,83,88,93,74,87,86,90,92,93,78,89,91,87,90,74,91,86,89,88,77,93,89,88,86,85,87,89,83,90
å…¬å¸H,82,73,87,82,76,89,83,81,78,84,87,69,83,79,84,86,87,72,83,85,81,84,69,85,81,84,83,71,86,84,83,81,80,82,84,77,85
å…¬å¸I,88,77,92,87,81,94,89,85,82,87,91,73,86,84,89,90,91,76,88,90,85,88,73,89,85,88,86,75,90,87,86,84,83,85,87,81,88
å…¬å¸J,86,75,90,85,79,92,87,83,80,85,89,71,84,82,87,88,89,74,85,87,83,86,71,87,83,86,84,73,88,85,84,83,82,84,86,79,87
"""

col1, col2 = st.columns(2)
with col1:
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ç¤ºä¾‹å±‚çº§æ–‡ä»¶ï¼ˆhierarchy_demo.csvï¼‰",
        data=example_hier.encode("utf-8-sig"),
        file_name="hierarchy_demo.csv",
        mime="text/csv",
        help="ç”¨äºæ¼”ç¤ºçš„å±‚çº§ç»“æ„æ–‡ä»¶ï¼Œå¯ç›´æ¥ä¸Šä¼ ä½“éªŒ AHP è®¡ç®—æµç¨‹"
    )
with col2:
    st.download_button(
        label="ğŸ“Š ä¸‹è½½ç¤ºä¾‹ä¼ä¸šå¾—åˆ†æ–‡ä»¶ï¼ˆcompany_scores_demo.csvï¼‰",
        data=example_scores.encode("utf-8-sig"),
        file_name="company_scores_demo.csv",
        mime="text/csv",
        help="ç”¨äºæ¼”ç¤ºçš„ä¼ä¸šÃ—ä¸‰çº§æŒ‡æ ‡æ‰“åˆ†æ•°æ®ï¼Œå¯ç›´æ¥ä¸Šä¼ ä½“éªŒç†µæƒä¸èåˆæµç¨‹"
    )

st.info("ğŸ’¡ å¦‚æœæ‚¨è¿˜æ²¡æœ‰å‡†å¤‡å¥½çš„æ•°æ®ï¼Œå¯ä»¥å…ˆä¸‹è½½ä¸Šæ–¹ç¤ºä¾‹æ–‡ä»¶ï¼Œå†ä¸Šä¼ ä»¥ä½“éªŒå®Œæ•´æµç¨‹ã€‚")


# -------------- Step 1: AHP pairwise per parent --------------
st.header("æ­¥éª¤ä¸€ï¼šAHP ä¸¤ä¸¤æ¯”è¾ƒ")
priorE = st.slider("RUC-AHP å…ˆéªŒï¼šç‰¹å¾å€¼æ³•", 0.0, 1.0, 0.4, 0.05)
priorA = st.slider("RUC-AHP å…ˆéªŒï¼šç®—æœ¯å¹³å‡æ³•", 0.0, 1.0, 0.3, 0.05)
priorG = st.slider("RUC-AHP å…ˆéªŒï¼šå‡ ä½•å¹³å‡æ³•", 0.0, 1.0, 0.3, 0.05)
metric = st.selectbox("åç¦»åº¦åº¦é‡", ["L1","L2"], index=0)
mode = st.selectbox("èåˆæ–¹å¼", ["geoï¼ˆä¹˜æ€§ï¼Œæ¨èï¼‰","linï¼ˆçº¿æ€§ï¼‰"], index=0)
mode_key = "geo" if mode.startswith("geo") else "lin"

def render_pairwise(node_ids, title_key):
    n = len(node_ids)
    st.markdown(f"**{title_key}** â€” æˆå‘˜ï¼š{[name_map[x] for x in node_ids]}")
    keyprefix = "m_"+title_key
    # initialize A in session
    if keyprefix not in st.session_state or st.session_state[keyprefix]["shape"]!=(n,n) or st.session_state[keyprefix]["ids"]!=tuple(node_ids):
        A = np.ones((n,n), dtype=float)
        st.session_state[keyprefix] = {"A":A, "shape":(n,n), "ids":tuple(node_ids)}
    else:
        A = st.session_state[keyprefix]["A"]

    with st.form("form_"+keyprefix):
        cols = st.columns(n+1)
        cols[0].markdown("**i/j**")
        for j in range(n): cols[j+1].markdown(f"**{name_map[node_ids[j]]}**")
        for i in range(n):
            row = st.columns(n+1)
            row[0].write(f"**{name_map[node_ids[i]]}**")
            for j in range(n):
                if i==j:
                    row[j+1].write("1")
                    A[i,j]=1.0
                elif i<j:
                    k = f"{keyprefix}_{i}_{j}"
                    default = float(A[i,j]) if A[i,j]!=1.0 else 1.0
                    v = row[j+1].number_input(f"{name_map[node_ids[i]]} vs {name_map[node_ids[j]]}",
                                              min_value=1.0, max_value=9.0, value=float(default), step=1.0, key=k)
                    A[i,j]=float(v); A[j,i]=1.0/float(v)
                else:
                    row[j+1].write(f"{A[i,j]:.3f}")
        st.form_submit_button("æ›´æ–°çŸ©é˜µ")
    st.session_state[keyprefix]["A"]=A

    # methods & fuse
    wE, lam, CI, CR = eig_weight_consistency(A)
    wA = row_arith_weight(A)
    wG = row_geo_weight(A)
    wf, gamma = ruc_fuse(wE,wA,wG,CR, prior=(priorE,priorA,priorG), metric=metric, mode=mode_key)

    df = pd.DataFrame({
        "id": node_ids,
        "name": [name_map[x] for x in node_ids],
        "E": wE, "A": wA, "G": wG, "fused": wf
    }).set_index("id")
    m1,m2,m3,m4 = st.columns(4)
    m1.metric("Î»_max", f"{lam:.4f}"); m2.metric("CI", f"{CI:.4f}")
    m3.metric("CR(â‰¤0.10ä¸ºä½³)", f"{CR:.4f}"); m4.metric("n", f"{n}")
    st.dataframe(df[["name","E","A","G","fused"]], use_container_width=True)
    return df["fused"]

# L1 matrix
st.subheader("â‘  ä¸€çº§ï¼šESG / KPI / DPI é‡è¦æ€§æ¯”è¾ƒ")
w_L1 = render_pairwise(L1_nodes["id"].tolist(), "Level1")

# L2 per parent
st.subheader("â‘¡ äºŒçº§ï¼šåœ¨å„è‡ªä¸€çº§ä¹‹ä¸‹çš„æ¯”è¾ƒ")
w_L2_local = {}
for pid, children in children_L1.items():
    with st.expander(f"çˆ¶èŠ‚ç‚¹ï¼š{name_map[pid]}ï¼ˆåŒ…å« {len(children)} ä¸ªäºŒçº§ï¼‰", expanded=False):
        w = render_pairwise(children, f"Level2_{pid}")
        w_L2_local.update(w.to_dict())

# L3 per parent
st.subheader("â‘¢ ä¸‰çº§ï¼šåœ¨å„è‡ªäºŒçº§ä¹‹ä¸‹çš„æ¯”è¾ƒ")
w_L3_local = {}
for pid, children in children_L2.items():
    with st.expander(f"çˆ¶èŠ‚ç‚¹ï¼ˆäºŒçº§ï¼‰ï¼š{name_map[pid]}ï¼ˆåŒ…å« {len(children)} ä¸ªä¸‰çº§ï¼‰", expanded=False):
        w = render_pairwise(children, f"Level3_{pid}")
        w_L3_local.update(w.to_dict())

# Compute global AHP weights for leaves
st.subheader("â‘£ è®¡ç®—ä¸‰çº§æŒ‡æ ‡å…¨å±€ AHP æƒé‡")
# First make series for L1 & L2
wL1 = pd.Series(w_L1.to_dict(), name="wL1")  # id->weight
wL2 = pd.Series(w_L2_local, name="wL2_local")
wL3 = pd.Series(w_L3_local, name="wL3_local")

# Build global mapping
global_ahp = {}
for leaf_id in L3_nodes["id"]:
    parent2 = L3_nodes[L3_nodes["id"]==leaf_id]["parent_id"].iloc[0]
    parent1 = L2_nodes[L2_nodes["id"]==parent2]["parent_id"].iloc[0]
    global_w = wL1[parent1]*wL2[parent2]*wL3[leaf_id]
    global_ahp[leaf_id] = global_w
global_ahp = pd.Series(global_ahp).sort_index()
global_ahp = global_ahp / (global_ahp.sum() if global_ahp.sum()>0 else 1.0)

df_RUC_AHP = pd.DataFrame({
    "id": global_ahp.index,
    "name": [name_map[x] for x in global_ahp.index],
    "type": [type_map.get(x,"benefit") for x in global_ahp.index],
    "RUC_AHP": global_ahp.values
}).set_index("id")
st.dataframe(df_RUC_AHP, use_container_width=True)

# ---------------- Step 2: Upload company scores ----------------
st.header("æ­¥éª¤äºŒï¼šä¸Šä¼ ä¼ä¸šÃ—ä¸‰çº§æŒ‡æ ‡å¾—åˆ†")
st.caption("è¦æ±‚ï¼šåˆ—åä¸ºå¶å­æŒ‡æ ‡ idï¼ˆå¦‚ T1..T37ï¼‰æˆ–ä¸­æ–‡åç§°ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ï¼‰ï¼Œè¡Œ=å…¬å¸")
scores_file = st.file_uploader("ä¸Šä¼  CSVï¼ˆCompanyåˆ— + 37åˆ—æŒ‡æ ‡ï¼‰", type=["csv"], key="scorescsv")
winsor = st.slider("Winsorize å»æå€¼ï¼ˆæ¯ç«¯ç™¾åˆ†æ¯”ï¼‰", 0.0, 20.0, 0.0, 1.0)

if scores_file is None:
    st.info("ç­‰å¾…ä¸Šä¼ å…¬å¸å¾—åˆ†è¡¨â€¦â€¦")
    st.stop()

df_scores = pd.read_csv(scores_file)
# Detect company col
first_col = df_scores.columns[0]
if first_col.lower() in ["company","firm","ä¼ä¸š","å…¬å¸","name"]:
    df_scores = df_scores.set_index(first_col)
# Try map columns by id or name
cols_by_id = [c for c in df_scores.columns if c in L3_nodes["id"].values]
if len(cols_by_id)==len(L3_nodes):
    S = df_scores[cols_by_id].copy()
else:
    # try by name -> id
    name_to_id = {name_map[i]:i for i in L3_nodes["id"]}
    try_cols = []
    for c in df_scores.columns:
        if c in name_to_id:
            try_cols.append(name_to_id[c])
    if len(try_cols)==len(L3_nodes):
        S = df_scores[ [name_map[i] for i in L3_nodes["id"]] ].copy()
        S.columns = L3_nodes["id"].tolist()
    else:
        st.error("åˆ—åéœ€ä¸º T1..T37 æˆ–å¯¹åº”ä¸­æ–‡åç§°ï¼Œä¸”å¿…é¡»å®Œæ•´åŒ¹é…ã€‚"); st.stop()

# Winsorize
if winsor>0:
    low, high = winsor, 100-winsor
    for col in S.columns:
        lo = np.nanpercentile(S[col].values, low)
        hi = np.nanpercentile(S[col].values, high)
        S[col] = S[col].clip(lo, hi)

st.write("åŸå§‹æ‰“åˆ†ï¼ˆSï¼‰")

# æ˜¾ç¤ºæ—¶å°†æŒ‡æ ‡ id æ›¿æ¢ä¸ºä¸­æ–‡å
S_display = S.copy()
S_display.columns = [name_map.get(c, c) for c in S.columns]
st.dataframe(S_display, use_container_width=True)


# ---------------- Step 3: Entropy weights ----------------
st.header("æ­¥éª¤ä¸‰ï¼šEntropy weightï¼ˆå®¢è§‚æƒé‡ï¼‰")
# Normalize per indicator with direction
Z = pd.DataFrame(index=S.index, columns=S.columns, dtype=float)
for col in S.columns:
    x = S[col].astype(float).values
    z = normalize_minmax(x)
    if type_map.get(col,"benefit")=="cost":
        z = 1.0 - z
    Z[col] = np.maximum(z, 0.0)

st.write("æ ‡å‡†åŒ–çŸ©é˜µ Zï¼ˆç”¨äºç†µæƒä¸åŠ æƒè¯„åˆ†ï¼‰")

# æ˜¾ç¤ºæ—¶å°†æŒ‡æ ‡ id æ›¿æ¢ä¸ºä¸­æ–‡å
Z_display = Z.copy()
Z_display.columns = [name_map.get(c, c) for c in Z.columns]
st.dataframe(Z_display, use_container_width=True)


m = Z.shape[0]; k = 1.0/np.log(m) if m>1 else 0.0
P = Z.div(Z.sum(axis=0).replace(0.0, np.nan), axis=1).fillna(0.0)
E = -k * (P.replace(0.0, np.nan).applymap(lambda v: v*np.log(v) if v>0 else 0.0)).sum(axis=0).fillna(0.0)
D = 1.0 - E
ENT = (D / (D.sum() if D.sum()>0 else 1.0)).rename("ENT")

# ========= æ˜¾ç¤ºæ—¶æ›¿æ¢åˆ—å =========
ENT_display = ENT.to_frame().copy()
ENT_display.index = [name_map.get(i, i) for i in ENT_display.index]
st.dataframe(ENT_display, use_container_width=True)


# ---------------- Step 4: Fusion ----------------
st.header("æ­¥éª¤å››ï¼šä¸»å®¢è§‚æƒé‡èåˆ")
alpha = st.slider("AHP å æ¯” Î±", 0.0, 1.0, 0.5, 0.05)
ahp_vec = df_RUC_AHP["RUC_AHP"].reindex(Z.columns).values
ent_vec = ENT.reindex(Z.columns).values
w_fused = (np.maximum(ahp_vec,1e-12)**alpha) * (np.maximum(ent_vec,1e-12)**(1-alpha))
w_fused = w_fused / (w_fused.sum() if w_fused.sum()>0 else 1.0)

weights_tbl = pd.DataFrame({
    "id": Z.columns,
    "name": [name_map[i] for i in Z.columns],
    "type": [type_map.get(i,"benefit") for i in Z.columns],
    "RUC_AHP": ahp_vec,
    "ENT": ENT.reindex(Z.columns).values,
    "FUSED": w_fused
}).set_index("id")
st.dataframe(weights_tbl, use_container_width=True)

# ---------------- Step 5: Final scores ----------------
st.header("æ­¥éª¤äº”ï¼šæœ€ç»ˆå…¬å¸ç»¼åˆå¾—åˆ†ä¸å¯¼å‡º")
final_scores = (Z * w_fused).sum(axis=1).to_frame(name="FinalScore").sort_values("FinalScore", ascending=False)
st.dataframe(final_scores, use_container_width=True)

# Downloads
buf_weights = io.BytesIO(weights_tbl.to_csv(index=True).encode("utf-8"))
buf_scores = io.BytesIO(final_scores.to_csv(index=True).encode("utf-8"))
st.download_button("ä¸‹è½½ æƒé‡è¡¨ (CSV)", data=buf_weights, file_name="weights_fused.csv", mime="text/csv")
st.download_button("ä¸‹è½½ å…¬å¸è¯„åˆ† (CSV)", data=buf_scores, file_name="company_scores.csv", mime="text/csv")

with st.expander("æ–¹æ³•è¯´æ˜ / Notes"):
    st.markdown("""
- **å¤šå±‚çº§ AHP**ï¼šæŒ‰çˆ¶èŠ‚ç‚¹é€å—ä¸¤ä¸¤æ¯”è¾ƒï¼Œè®¡ç®—æœ¬åœ°æƒé‡ä¸ CRï¼›é€šè¿‡ RUC-AHP ç¨³å¥èåˆå¾—åˆ°æ¯å—çš„æœ¬åœ°æƒé‡ï¼›å±‚å±‚ç›¸ä¹˜å¾—åˆ°**ä¸‰çº§å…¨å±€ AHP æƒé‡**ã€‚
- **Entropy weight**ï¼šåŸºäºä¼ä¸šÃ—æŒ‡æ ‡å¾—åˆ†çš„æ ‡å‡†åŒ–çŸ©é˜µ Z è®¡ç®—å®¢è§‚æƒé‡ ENTã€‚æˆæœ¬å‹æŒ‡æ ‡è‡ªåŠ¨åšæ–¹å‘åè½¬ã€‚
- **ä¸»å®¢è§‚èåˆ**ï¼š`w âˆ (AHP^Î±)*(ENT^(1-Î±))`ï¼Œé»˜è®¤ Î±=0.5ï¼ˆç›¸ä¹˜å¼€å¹³æ–¹ï¼‰ã€‚
- **æœ€ç»ˆå¾—åˆ†**ï¼š`Score(company) = Î£ w_i * Z_{company,i}`ã€‚
""")
